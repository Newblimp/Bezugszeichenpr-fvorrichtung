#!/usr/bin/env python3
"""
Compress ONNX models with zlib and generate C++ source file with embedded data.

Usage:
    python compress_models.py --det models/det.onnx --rec models/rec.onnx --output resources/models_compressed.cpp
"""

import argparse
import zlib
import os
import sys


def compress_file(filepath: str) -> tuple[bytes, int]:
    """Compress a file using zlib and return (compressed_data, original_size)."""
    if not os.path.exists(filepath):
        print(f"Warning: File not found: {filepath}", file=sys.stderr)
        return b"", 0

    with open(filepath, "rb") as f:
        original_data = f.read()

    original_size = len(original_data)
    compressed_data = zlib.compress(original_data, level=9)
    compressed_size = len(compressed_data)

    ratio = (compressed_size / original_size) * 100 if original_size > 0 else 0
    print(f"  {os.path.basename(filepath)}: {original_size:,} -> {compressed_size:,} bytes ({ratio:.1f}%)")

    return compressed_data, original_size


def bytes_to_cpp_array(data: bytes, bytes_per_line: int = 16) -> str:
    """Convert bytes to C++ array initializer string."""
    if not data:
        return "    0x00"

    lines = []
    for i in range(0, len(data), bytes_per_line):
        chunk = data[i : i + bytes_per_line]
        hex_values = ", ".join(f"0x{b:02x}" for b in chunk)
        lines.append(f"    {hex_values}")

    return ",\n".join(lines)


def generate_cpp_file(
    det_data: bytes,
    det_original_size: int,
    rec_data: bytes,
    rec_original_size: int,
    output_path: str,
) -> None:
    """Generate C++ source file with embedded compressed model data."""

    cpp_content = f"""// Auto-generated file - DO NOT EDIT
// Generated by cmake/compress_models.py
// Contains zlib-compressed PaddleOCR ONNX models

#include <cstdint>
#include <cstddef>

// Detection model (det.onnx) - compressed with zlib level 9
// Original size: {det_original_size:,} bytes
// Compressed size: {len(det_data):,} bytes
const uint8_t det_model_compressed[] = {{
{bytes_to_cpp_array(det_data)}
}};
const size_t det_model_compressed_size = {len(det_data)};
const size_t det_model_uncompressed_size = {det_original_size};

// Recognition model (rec.onnx) - compressed with zlib level 9
// Original size: {rec_original_size:,} bytes
// Compressed size: {len(rec_data):,} bytes
const uint8_t rec_model_compressed[] = {{
{bytes_to_cpp_array(rec_data)}
}};
const size_t rec_model_compressed_size = {len(rec_data)};
const size_t rec_model_uncompressed_size = {rec_original_size};
"""

    # Create output directory if needed
    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    with open(output_path, "w") as f:
        f.write(cpp_content)

    print(f"Generated: {output_path}")
    total_compressed = len(det_data) + len(rec_data)
    total_original = det_original_size + rec_original_size
    print(f"Total: {total_original:,} -> {total_compressed:,} bytes")


def main():
    parser = argparse.ArgumentParser(description="Compress ONNX models for embedding")
    parser.add_argument("--det", required=True, help="Path to detection model (det.onnx)")
    parser.add_argument("--rec", required=True, help="Path to recognition model (rec.onnx)")
    parser.add_argument("--output", required=True, help="Output C++ file path")
    args = parser.parse_args()

    print("Compressing OCR models...")

    det_data, det_original_size = compress_file(args.det)
    rec_data, rec_original_size = compress_file(args.rec)

    generate_cpp_file(det_data, det_original_size, rec_data, rec_original_size, args.output)

    print("Done!")


if __name__ == "__main__":
    main()
